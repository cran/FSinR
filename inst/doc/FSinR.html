<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Francisco Aragón Royón" />

<meta name="date" content="2025-10-15" />

<title>A Short Introduction to the FSinR Package</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">A Short Introduction to the FSinR
Package</h1>
<h4 class="author">Francisco Aragón Royón</h4>
<h4 class="date">2025-10-15</h4>



<div id="introduction" class="section level3">
<h3>1. Introduction</h3>
<p>The package <strong>FSinR</strong> contains functions to perform the
feature selection process. More specifically, it contains a large number
of filter and wrapper methods widely used in the literature that are
combined with search algorithms in order to obtain an optimal subset of
features. The FSinR package uses the functions for training
classification and regression models available in the R caret package to
generate wrapper measures. This gives the package a great background of
methods and functionalities. In addition, the package has been
implemented in such a way that its use is as easy and intuitive as
possible. This is why the package contains a number of high-level
functions from which any search algorithm or filter/wrapper method can
be called.</p>
<p>The way to install the package from the CRAN repository is as
follows:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;FSinR&quot;</span>)</span></code></pre></div>
</div>
<div id="feature-selection-process" class="section level3">
<h3>2. Feature Selection Process</h3>
<p>As mentioned above, the feature selection process aims to obtain an
optimal subset of features. To do this, a search algorithm is combined
with a filter/wrapper method. The search algorithm guides the process in
the features space according to the results returned by the
filter/wrapper methods of the evaluated subsets. The optimal subset of
features obtained in this process is very useful to generate simpler
models, which require less computational resources and which present a
better final performance.</p>
<p>The feature selection process is done with the
<code>featureSelection</code> function. This is the main function of the
package and its parameters are:</p>
<ul>
<li>data: a matrix or data.frame with the dataset</li>
<li>class: the name of the dependent variable</li>
<li>searcher: the search algorithm</li>
<li>evaluator: the evaluation method (filter or wrapper method)</li>
</ul>
<p>The result of this function mainly returns the best subset of
features found and the measure value of that subset. In addition, it
returns another group of variables such as the execution time, etc.</p>
<div id="search-algorithms" class="section level4">
<h4>2.1. Search algorithms</h4>
<p>The search functions present in the package are the following:</p>
<ol style="list-style-type: decimal">
<li>Sequential forward selection</li>
<li>Sequential floating forward selection</li>
<li>Sequential backward selection</li>
<li>Sequential floating backward selection</li>
<li>Breadth first search</li>
<li>Deep first search</li>
<li>Genetic algorithm</li>
<li>Whale optimization algorithm</li>
<li>Ant colony optimization</li>
<li>Simulated annealing</li>
<li>Tabu search</li>
<li>Hill-Climbing</li>
<li>Las Vegas wrapper</li>
</ol>
<p>The package contains a function, <code>searchAlgorithm</code>, which
allows you to select the search algorithm to be used in the feature
selection process. The function consists of the following
parameters:</p>
<ul>
<li>searcher: the name of the search algorithm</li>
<li>params: a list of specific parameters for each algorithm</li>
</ul>
<p>The result of the call to this function is another function to be
used in the main function as a search algorithm.</p>
</div>
<div id="filter-methods" class="section level4">
<h4>2.2. Filter methods</h4>
<p>The filter methods implemented in the package are:</p>
<ol style="list-style-type: decimal">
<li>Chi-squared</li>
<li>Cramer V</li>
<li>F-score</li>
<li>Relief</li>
<li>Rough Sets consistency</li>
<li>Binary consistency</li>
<li>Inconsistent Examples consistency</li>
<li>Inconsistent Examples Pairs consistency</li>
<li>Determination Coefficient</li>
<li>Mutual information</li>
<li>Gain ratio</li>
<li>Symmetrical uncertain</li>
<li>Gini index</li>
<li>Jd</li>
<li>MDLC</li>
<li>ReliefFeatureSetMeasure</li>
</ol>
<p>The <code>filterEvaluator</code> function allows you to select a
filter method from the above. The function has the parameters:</p>
<ul>
<li>filter: the name of the filter method</li>
<li>params: a list of specific parameters for each method</li>
</ul>
<p>The result of the function call is a function that is used as a
filter evaluation method in the main function,
<code>featureSelection</code>.</p>
</div>
<div id="wrapper-methods" class="section level4">
<h4>2.3. Wrapper methods</h4>
<p>The FSinR package allows the possibility of using the 238 models
available in the caret package as wrapper methods. The complete list of
caret models can be found <a href="https://topepo.github.io/caret/available-models.html">here</a>. In
addition, the caret package offers the possibility of establishing a
group of options to personalize the models (eg. resampling techniques,
evaluation measurement, grid parameters, …) using the
<code>trainControl</code> and <code>train</code> functions. In FSinR,
the <code>wrapperEvaluator</code> function is used to set all these
parameters and use them to generate the wrapper model using as
background the functions of caret. The <code>wrapperEvaluator</code>
function has as parameters:</p>
<ul>
<li>learner: model name of those available in caret</li>
<li>resamplingParams: list of parameters for <code>trainControl</code>
function</li>
<li>fittingParams: list of parameters for <code>train</code> function
(x, y, method and trainControl not neccesary)</li>
</ul>
<p>The result of this function is another function that is used as a
wrapper evaluation measure in the main function.</p>
</div>
<div id="feature-selection-process-example" class="section level4">
<h4>2.4. Feature Selection process example</h4>
<p>To demonstrate in a simple manner how package works, the iris dataset
will be used in this example.</p>
<p>It is important to note that the FSinR package does not divide data
into training and test data. Instead, it applies the feature selection
process to the entire dataset passed to it as a parameter. Therefore, in
a modeling process the user should divide the dataset prior to
performing the feature selection process. Missing data must also be
processed prior to the use of the package. But since the main purpose of
this vignette is to illustrate the use of the package and not the entire
modeling process, in this case the entire unpartitioned dataset will be
used.</p>
<p>The iris dataset consists in 150 instances of 4 variables
(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width) that determine
the type of iris plant. The target variable, Species, has 3 possible
classes (setosa, versicolor, virginica).</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a><span class="fu">library</span>(FSinR)</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a><span class="fu">data</span>(iris)</span></code></pre></div>
<div id="search-wrapper" class="section level5">
<h5>2.4.1. Search + Wrapper</h5>
<p>Next we will illustrate an example of feature selection composed of a
search algorithm and a wrapper method.</p>
<p>First, the wrapper method must be generated. To do this, you have to
call the <code>wrapperEvaluator</code> function and determine which
model you want to use as a wrapper method. Since the iris problem is a
classification problem, in the example we use a knn model.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a>evaluator <span class="ot">&lt;-</span> <span class="fu">wrapperEvaluator</span>(<span class="st">&quot;knn&quot;</span>)</span></code></pre></div>
<p>The next step is to generate the search algorithm. This is done by
calling the <code>searchAlgorithm</code> function and specifying the
algorithm you want to use. In this case we are going to use as a search
algorithm a sequential search,
<code>sequentialForwardSelection</code>.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a>searcher <span class="ot">&lt;-</span> <span class="fu">searchAlgorithm</span>(<span class="st">&#39;sequentialForwardSelection&#39;</span>)</span></code></pre></div>
<p>Once we have generated the search algorithm and the wrapper method we
call the main function that performs the feature selection process.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">featureSelection</span>(iris, <span class="st">&#39;Species&#39;</span>, searcher, evaluator)</span></code></pre></div>
<p>The results show the best subset of features found and its
evaluation.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a>results<span class="sc">$</span>bestFeatures</span>
<span id="cb6-2"><a href="#cb6-2" tabindex="-1"></a><span class="co">#&gt;      Sepal.Length Sepal.Width Petal.Length Petal.Width</span></span>
<span id="cb6-3"><a href="#cb6-3" tabindex="-1"></a><span class="co">#&gt; [1,]            0           1            1           1</span></span>
<span id="cb6-4"><a href="#cb6-4" tabindex="-1"></a>results<span class="sc">$</span>bestValue</span>
<span id="cb6-5"><a href="#cb6-5" tabindex="-1"></a><span class="co">#&gt; [1] 0.9645521</span></span></code></pre></div>
<p>The above example illustrates a simple use of the package, but this
can also be more complex if you intend to establish certain parameters.
Regarding the wrapper method, it is possible to tune the model
parameters. In the first instance, you can establish the resampling
parameters, which are the same arguments that are passed to the
<code>trainControl</code> function of the caret package. Secondly, you
can establish the fitting parameters, which are the same as for the
caret <code>train</code> function.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>resamplingParams <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb7-2"><a href="#cb7-2" tabindex="-1"></a>fittingParams <span class="ot">&lt;-</span> <span class="fu">list</span>(<span class="at">preProc =</span> <span class="fu">c</span>(<span class="st">&quot;center&quot;</span>, <span class="st">&quot;scale&quot;</span>), <span class="at">metric=</span><span class="st">&quot;Accuracy&quot;</span>, <span class="at">tuneGrid =</span> <span class="fu">expand.grid</span>(<span class="at">k =</span> <span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>)))</span>
<span id="cb7-3"><a href="#cb7-3" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" tabindex="-1"></a>evaluator <span class="ot">&lt;-</span> <span class="fu">wrapperEvaluator</span>(<span class="st">&quot;knn&quot;</span>, resamplingParams, fittingParams)</span></code></pre></div>
<p>For more details, the way in which caret train and tune a model can
be seen <a href="https://topepo.github.io/caret/model-training-and-tuning.html">here</a>.
Note that the FSinR package is able to detect automatically depending on
the metric whether the objective of the problem is to maximize or
minimize.</p>
<p>As for the search algorithm, it is also possible to establish a
certain number of parameters. These parameters are specific to each
search algorithm. If in this case we now use a tabu search, the number
of algorithm iterations, the size of the taboo list, as well as an
intensification phase and a diversification phase, among others can be
established.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>searcher <span class="ot">&lt;-</span> <span class="fu">searchAlgorithm</span>(<span class="st">&#39;tabu&#39;</span>, <span class="fu">list</span>(<span class="at">tamTabuList =</span> <span class="dv">4</span>, <span class="at">iter =</span> <span class="dv">5</span>, <span class="at">intensification=</span><span class="dv">2</span>, <span class="at">iterIntensification=</span><span class="dv">5</span>, <span class="at">diversification=</span><span class="dv">1</span>, <span class="at">iterDiversification=</span><span class="dv">5</span>, <span class="at">verbose=</span><span class="cn">FALSE</span>) )</span></code></pre></div>
<p>Most FSinR package search algorithms include a parameter called
verbose, which if set to TRUE shows the development and information of
the iterations of the algorithms per console. It is important for tabu
search to note that the number of neighbors that are considered and
evaluated in each iteration of the tabu search algorithm,
<code>numNeigh</code>, is set by default to as many as there are. Then
it should be noted that a high value of this parameter considerably
increases the calculation time.</p>
<p>Finally, the feature selection process is run again.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">featureSelection</span>(iris, <span class="st">&#39;Species&#39;</span>, searcher, evaluator)</span></code></pre></div>
</div>
<div id="search-filter" class="section level5">
<h5>2.4.2. Search + Filter</h5>
<p>This example is very similar to the previous one. The main difference
is to generate a filter method as an evaluator instead of a wrapper
method. This is done with the function <code>filterEvaluator</code>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a>evaluator <span class="ot">&lt;-</span> <span class="fu">filterEvaluator</span>(<span class="st">&#39;MDLC&#39;</span>)</span></code></pre></div>
<p>The search algorithm is then generated:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a>searcher <span class="ot">&lt;-</span> <span class="fu">searchAlgorithm</span>(<span class="st">&#39;sequentialForwardSelection&#39;</span>)</span></code></pre></div>
<p>And finally the feature selection process is performed, passing to
the <code>featureSelection</code> function the filter method and the
search algorithm generated.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">featureSelection</span>(iris, <span class="st">&#39;Species&#39;</span>, searcher, evaluator)</span></code></pre></div>
<p>Again, the best subset obtained and the value obtained by the
evaluation measure are shown as results.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a>results<span class="sc">$</span>bestFeatures</span>
<span id="cb13-2"><a href="#cb13-2" tabindex="-1"></a><span class="co">#&gt;      Sepal.Length Sepal.Width Petal.Length Petal.Width</span></span>
<span id="cb13-3"><a href="#cb13-3" tabindex="-1"></a><span class="co">#&gt; [1,]            0           1            0           0</span></span>
<span id="cb13-4"><a href="#cb13-4" tabindex="-1"></a>results<span class="sc">$</span>bestValue</span>
<span id="cb13-5"><a href="#cb13-5" tabindex="-1"></a><span class="co">#&gt; [1] 98.96749</span></span></code></pre></div>
<p>As in the previous example, in this case you can establish both the
parameters of the search algorithms and the filter methods if the
functions have them.</p>
</div>
<div id="individual-evaluation-of-features" class="section level5">
<h5>2.4.3. Individual evaluation of features</h5>
<p>Advanced use of the package allows individual evaluation of a set of
features using the filter/wrapper methods. That is, the filter/wrapper
methods can be used directly without the need to include them in a
search algorithm. This is not a defined high-level functionality within
the package, since an individual evaluation is not a feature selection
process itself. But it is a functionality that can be realized and has
to be taken into consideration.</p>
<p>To do this, an evaluator must be generated using a filter method or a
wrapper method.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" tabindex="-1"></a>filter_evaluator <span class="ot">&lt;-</span> <span class="fu">filterEvaluator</span>(<span class="st">&quot;IEConsistency&quot;</span>)</span>
<span id="cb14-2"><a href="#cb14-2" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" tabindex="-1"></a>wrapper_evaluator <span class="ot">&lt;-</span> <span class="fu">wrapperEvaluator</span>(<span class="st">&quot;lvq&quot;</span>)</span></code></pre></div>
<p>And then obtain a measure from the evaluator by passing as a
parameter the dataset, the name of the dependent variable and the set of
features to be evaluated.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" tabindex="-1"></a>resultFilter <span class="ot">&lt;-</span> <span class="fu">filter_evaluator</span>(iris, <span class="st">&#39;Species&#39;</span>, <span class="fu">c</span>(<span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Sepal.Width&quot;</span>,  <span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>))</span>
<span id="cb15-2"><a href="#cb15-2" tabindex="-1"></a><span class="co">#&gt; Warning in filter_evaluator(iris, &quot;Species&quot;, c(&quot;Sepal.Length&quot;, &quot;Sepal.Width&quot;, :</span></span>
<span id="cb15-3"><a href="#cb15-3" tabindex="-1"></a><span class="co">#&gt; The data seems not to be discrete, as it should be</span></span>
<span id="cb15-4"><a href="#cb15-4" tabindex="-1"></a>resultFilter</span>
<span id="cb15-5"><a href="#cb15-5" tabindex="-1"></a><span class="co">#&gt; [1] 1</span></span>
<span id="cb15-6"><a href="#cb15-6" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" tabindex="-1"></a>resultWrapper <span class="ot">&lt;-</span> <span class="fu">wrapper_evaluator</span>(iris, <span class="st">&#39;Species&#39;</span>, <span class="fu">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>))</span>
<span id="cb15-8"><a href="#cb15-8" tabindex="-1"></a>resultWrapper</span>
<span id="cb15-9"><a href="#cb15-9" tabindex="-1"></a><span class="co">#&gt; [1] 0.9600169</span></span></code></pre></div>
</div>
</div>
</div>
<div id="direct-feature-selection-process" class="section level3">
<h3>3. Direct Feature Selection Process</h3>
<p>In this case, the feature selection process consists of a direct
search algorithm (cut-off method) combined with an evaluator based on
filter or wrapper methods.</p>
<p>The direct feature selection process is performed using the
<code>directFeatureSelection</code> function. This function contains the
same parameters as the <code>featureSelection</code> function, with the
difference that the searcher parameter is replaced by the directSearcher
parameter. This parameter contains a direct search algorithm.</p>
<p>The function mainly returns the selected subset of features, and the
value of the individual evaluation of each of these features.</p>
<div id="direct-search-algorithms" class="section level4">
<h4>3.1. Direct search algorithms</h4>
<p>The direct search functions present in the package are the
following:</p>
<ol style="list-style-type: decimal">
<li>Select k best</li>
<li>Select percentile</li>
<li>Select threshold</li>
<li>Select threshold range</li>
<li>Select difference</li>
<li>Select slope</li>
</ol>
<p>The package contains the <code>directSearchAlgorithm</code> function
that allows you to select the direct search algorithm to be used. The
parameters are the same as the <code>searchAlgorithm</code> function,
except that the searcher parameter is replaced by the directSearcher
parameter. This parameter contains the name of the chosen cut-off
method.</p>
<p>The result of the call to this function is another function to be
used in the main function as a direct search algorithm.</p>
</div>
<div id="direct-feature-selection-process-example" class="section level4">
<h4>3.2. Direct Feature Selection process example</h4>
<p>In the previous example we showed the functionality of the package on
a classification example. In this example we are going to show a
regression example. For this we use the mtcars dataset, composed of 32
instances of 10 variables. The regression problem consists in
forecasting the value of the mpg variable.</p>
<p>Compared to the process in the previous example, to perform a direct
feature selection process the main change is that in this case a direct
search algorithm has to be generated. In addition, the function for
performing the feature selection process also changes to
<code>directFeatureSelection</code>. While the generation of the filter
or wrapper methods remains the same.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb16-2"><a href="#cb16-2" tabindex="-1"></a><span class="fu">library</span>(FSinR)</span>
<span id="cb16-3"><a href="#cb16-3" tabindex="-1"></a></span>
<span id="cb16-4"><a href="#cb16-4" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb16-5"><a href="#cb16-5" tabindex="-1"></a></span>
<span id="cb16-6"><a href="#cb16-6" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" tabindex="-1"></a>evaluator <span class="ot">&lt;-</span> <span class="fu">filterEvaluator</span>(<span class="st">&#39;determinationCoefficient&#39;</span>)</span>
<span id="cb16-8"><a href="#cb16-8" tabindex="-1"></a></span>
<span id="cb16-9"><a href="#cb16-9" tabindex="-1"></a>directSearcher <span class="ot">&lt;-</span> <span class="fu">directSearchAlgorithm</span>(<span class="st">&#39;selectKBest&#39;</span>, <span class="fu">list</span>(<span class="at">k=</span><span class="dv">3</span>))</span>
<span id="cb16-10"><a href="#cb16-10" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">directFeatureSelection</span>(mtcars, <span class="st">&#39;mpg&#39;</span>, directSearcher, evaluator)</span>
<span id="cb16-12"><a href="#cb16-12" tabindex="-1"></a>results<span class="sc">$</span>bestFeatures</span>
<span id="cb16-13"><a href="#cb16-13" tabindex="-1"></a><span class="co">#&gt;      cyl disp hp drat wt qsec vs am gear carb</span></span>
<span id="cb16-14"><a href="#cb16-14" tabindex="-1"></a><span class="co">#&gt; [1,]   1    1  0    0  1    0  0  0    0    0</span></span>
<span id="cb16-15"><a href="#cb16-15" tabindex="-1"></a>results<span class="sc">$</span>featuresSelected</span>
<span id="cb16-16"><a href="#cb16-16" tabindex="-1"></a><span class="co">#&gt; [1] &quot;wt&quot;   &quot;cyl&quot;  &quot;disp&quot;</span></span>
<span id="cb16-17"><a href="#cb16-17" tabindex="-1"></a>results<span class="sc">$</span>valuePerFeature</span>
<span id="cb16-18"><a href="#cb16-18" tabindex="-1"></a><span class="co">#&gt; [1] 0.7528328 0.7261800 0.7183433</span></span></code></pre></div>
</div>
</div>
<div id="hybrid-feature-selection-process" class="section level3">
<h3>4. Hybrid Feature Selection Process</h3>
<p>The hybrid feature selection process is composed by a hybrid search
algorithm that combines the measures obtained from 2 evaluators. This
process is performed with the <code>hybridFeatureSelection</code>
function. The parameters of this function are as follows:</p>
<ul>
<li>data: a matrix or data.frame with the dataset</li>
<li>class: the name of the dependent variable</li>
<li>hybridSearcher: the hybrid search algorithm</li>
<li>evaluator_1: the first evaluation method (filter or wrapper
method)</li>
<li>evaluator_2: the second evaluation method (filter or wrapper
method)</li>
</ul>
<p>The function returns again the best subset of features found and
their measure among other values.</p>
<div id="hybrid-search-algorithms" class="section level4">
<h4>4.1. Hybrid search algorithms</h4>
<p>The hybrid search function present in the package is the
following:</p>
<ol style="list-style-type: decimal">
<li>Linear Consistency-Constrained (LCC)</li>
</ol>
<p>The package contains the <code>hybridSearchAlgorithm</code> function
that allows you to select this hybrid search function. The parameters
are the same as the <code>searchAlgorithm</code> and
<code>directSearchAlgorithm</code> function, except that the searcher
(directSearcher) parameter is replaced by the hybridSearcher parameter.
This parameter contains the name of the chosen hybrid method.</p>
<p>The result of the call to this function is another function to be
used in the main function as a hybrid search algorithm.</p>
</div>
<div id="hybrid-feature-selection-process-example" class="section level4">
<h4>4.2. Hybrid Feature Selection process example</h4>
<p>In this example we continue with the previous regression example.</p>
<p>The hybrid feature selection process is slightly different from the
above. This is because in addition to generating a hybrid search
algorithm, two evaluators must be generated. The package only implements
a hybrid search algorithm, LCC. This algorithm requires a first
evaluator to evaluate the features individually, and a second evaluator
to evaluate the features conjunctively.</p>
<p>The package implements different filter/wrapper methods focused on
individual feature evaluation or set evaluation. Set evaluation methods
can also evaluate features individually. But individual evaluation
methods (Cramer, Chi squared, F-Score and Relief) cannot evaluate sets
of features. Therefore, to perform a hybrid feature selection process, a
hybrid search algorithm has to be generated together with an individual
feature evaluator (individual or set evaluation method) and a set
evaluator (set evaluation method)</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb17-2"><a href="#cb17-2" tabindex="-1"></a><span class="fu">library</span>(FSinR)</span>
<span id="cb17-3"><a href="#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="#cb17-4" tabindex="-1"></a><span class="fu">data</span>(mtcars)</span>
<span id="cb17-5"><a href="#cb17-5" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" tabindex="-1"></a>evaluator_1 <span class="ot">&lt;-</span> <span class="fu">filterEvaluator</span>(<span class="st">&#39;determinationCoefficient&#39;</span>)</span>
<span id="cb17-8"><a href="#cb17-8" tabindex="-1"></a>evaluator_2 <span class="ot">&lt;-</span> <span class="fu">filterEvaluator</span>(<span class="st">&#39;ReliefFeatureSetMeasure&#39;</span>)</span>
<span id="cb17-9"><a href="#cb17-9" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" tabindex="-1"></a>hybridSearcher <span class="ot">&lt;-</span> <span class="fu">hybridSearchAlgorithm</span>(<span class="st">&#39;LCC&#39;</span>)</span>
<span id="cb17-11"><a href="#cb17-11" tabindex="-1"></a></span>
<span id="cb17-12"><a href="#cb17-12" tabindex="-1"></a>results <span class="ot">&lt;-</span> <span class="fu">hybridFeatureSelection</span>(mtcars, <span class="st">&#39;mpg&#39;</span>, hybridSearcher, evaluator_1, evaluator_2)</span>
<span id="cb17-13"><a href="#cb17-13" tabindex="-1"></a>results<span class="sc">$</span>bestFeatures</span>
<span id="cb17-14"><a href="#cb17-14" tabindex="-1"></a><span class="co">#&gt;      cyl disp hp drat wt qsec vs am gear carb</span></span>
<span id="cb17-15"><a href="#cb17-15" tabindex="-1"></a><span class="co">#&gt; [1,]   1    1  1    1  1    1  1  1    1    1</span></span>
<span id="cb17-16"><a href="#cb17-16" tabindex="-1"></a>results<span class="sc">$</span>bestValue</span>
<span id="cb17-17"><a href="#cb17-17" tabindex="-1"></a><span class="co">#&gt; [1] -0.01607143</span></span></code></pre></div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
